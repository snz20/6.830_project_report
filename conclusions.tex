
\section{Conclusions \& Future Work}
\label{sec:con}
In this project, we aimed at contributing to MADlib by implementing two algorithms namely, Genetic Programming for Symbolic Regression and Adaptive Boosting for Binary Classification. We implemented the algorithms as MADlib modules, more specifically as Python driver UDFs inside PostgreSQL database. We tried to analyze the performance of these algorithms in a number of different settings. From the benchmarks we did, we initially found that, the runtime of both of the algorithms increases as we increase the number of independent variables (e.g., number of individuals in population or number of iterations for boosting). Running the algorithms using MADlib takes more time than bypassing MADlib altogether when data can be fit into memory. Running the algorithms using MADlib is advantageous when the dataset cannot be fit into memory. Batched execution is more efficient than row-by-row execution in terms of run time. As we increase batch size (i.e. decrease number of batches) we can see a decrease in runtimes of the algorithms. Also, it is more efficient than reading the whole dataset into memory in terms of memory usage. However, we were faced with the issue that, the im-memory implementation of both the algorithms take more time inside MADlib which needs further investigation. 

~~\\
Our ultimate goal is to contribute our code to the MADlib codebase: we have already established contact with the core developers through the official MADlib mailing-list. In future, we plan to incorporate parallelism in these algorithms. Right now our implementation works only with PostgreSQL. We would like to add support for Greenplum, as MADlib is also compatible with it, and take advantage of their native parallelism. 
